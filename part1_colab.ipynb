{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ¾ Rice Classification | Part 1: Data Exploration & Preprocessing\n",
    "**Arborio vs Jasmine â€” Binary Classification**\n",
    "\n",
    "**Run order:** This notebook â†’ Part 2 â†’ Part 3\n",
    "\n",
    "> ðŸ“¥ **Before running:** Upload `Rice_MSC_Dataset.csv` to your Colab session\n",
    "> or mount Google Drive and update the file path in Cell 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 1: Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='Set2')\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print('âœ… Libraries ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 2: Load & Filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# If using Google Drive: from google.colab import drive; drive.mount('/content/drive')\n",
    "# Then update path: pd.read_csv('/content/drive/MyDrive/Rice_MSC_Dataset.csv')\n",
    "\n",
    "full_df = pd.read_csv('Rice_MSC_Dataset.csv')\n",
    "\n",
    "# Keep only the two varieties we care about\n",
    "rice_df = full_df[full_df['CLASS'].isin(['Arborio', 'Jasmine'])].copy()\n",
    "\n",
    "# Encode labels as numbers â€” ML models need numeric targets\n",
    "rice_df['label'] = rice_df['CLASS'].map({'Arborio': 0, 'Jasmine': 1})\n",
    "\n",
    "feature_columns = [c for c in rice_df.columns if c not in ['CLASS', 'label']]\n",
    "\n",
    "print(f'Dataset shape: {rice_df.shape}')\n",
    "print(f'Features ({len(feature_columns)}): {feature_columns}')\n",
    "print(f'\\nClass counts:\\n{rice_df[\"CLASS\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 3: Dataset Statistics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('Feature statistics:')\n",
    "print(rice_df[feature_columns].describe().round(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 4: Class Balance Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "counts = rice_df['CLASS'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "counts.plot(kind='bar', ax=axes[0], color=['#4C72B0','#DD8452'], edgecolor='black', rot=0)\n",
    "axes[0].set_title('Sample Count per Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "for bar in axes[0].patches:\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 30,\n",
    "                 f'{int(bar.get_height()):,}', ha='center', fontweight='bold')\n",
    "\n",
    "axes[1].pie(counts, labels=counts.index, autopct='%1.1f%%',\n",
    "            colors=['#4C72B0','#DD8452'], startangle=90)\n",
    "axes[1].set_title('Class Distribution')\n",
    "\n",
    "plt.suptitle('Class Balance Check', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ratio = counts.max() / counts.min()\n",
    "print(f'Imbalance ratio: {ratio:.2f}x â€” {\"âœ… Balanced\" if ratio < 1.5 else \"âš ï¸ Consider balancing techniques\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 5: Missing Value Check & Handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "missing = rice_df[feature_columns].isnull().sum()\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print('âœ… No missing values found')\n",
    "else:\n",
    "    for col in missing[missing > 0].index:\n",
    "        pct = missing[col] / len(rice_df) * 100\n",
    "        if pct < 30:\n",
    "            rice_df[col] = rice_df[col].fillna(rice_df[col].median())\n",
    "            print(f'Filled \"{col}\" with median ({pct:.1f}% missing)')\n",
    "        else:\n",
    "            rice_df.drop(columns=[col], inplace=True)\n",
    "            feature_columns.remove(col)\n",
    "            print(f'Dropped \"{col}\" ({pct:.1f}% missing â€” too high to impute)')\n",
    "\n",
    "    print('âœ… Missing value handling complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 6: Outlier Detection & Capping (IQR Method) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# IQR = middle 50% of the data. Values beyond 1.5Ã—IQR from Q1/Q3 = outlier.\n",
    "# We cap (clip) rather than delete to preserve sample size.\n",
    "\n",
    "outlier_counts = {}\n",
    "for col in feature_columns:\n",
    "    Q1, Q3 = rice_df[col].quantile([0.25, 0.75])\n",
    "    IQR    = Q3 - Q1\n",
    "    lo, hi = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "    n_out  = ((rice_df[col] < lo) | (rice_df[col] > hi)).sum()\n",
    "    outlier_counts[col] = n_out\n",
    "    rice_df[col] = np.clip(rice_df[col], lo, hi)  # Clip to fence values\n",
    "\n",
    "print('Outliers detected and capped per feature:')\n",
    "for col, count in outlier_counts.items():\n",
    "    print(f'  {col}: {count}')\n",
    "print(f'\\nData shape unchanged: {rice_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 7: Outlier Box Plots â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_cols = 3\n",
    "n_rows = (len(feature_columns) + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(feature_columns):\n",
    "    rice_df.boxplot(column=feat, by='CLASS', ax=axes[i],\n",
    "                    medianprops=dict(color='red', linewidth=2),\n",
    "                    flierprops=dict(marker='o', markerfacecolor='orange', markersize=3, alpha=0.5))\n",
    "    axes[i].set_title(feat, fontsize=9, fontweight='bold')\n",
    "    axes[i].set_xlabel('')\n",
    "\n",
    "for j in range(i+1, len(axes)): axes[j].set_visible(False)\n",
    "plt.suptitle('Feature Distributions by Class (after outlier capping)', fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 8: EDA â€” Visualisation 1: Overlapping Histograms â”€â”€â”€â”€â”€â”€â”€\n",
    "arborio = rice_df[rice_df['CLASS'] == 'Arborio']\n",
    "jasmine  = rice_df[rice_df['CLASS'] == 'Jasmine']\n",
    "\n",
    "n_rows = (len(feature_columns) + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(feature_columns):\n",
    "    axes[i].hist(arborio[feat], bins=40, alpha=0.6, label='Arborio', color='#4C72B0')\n",
    "    axes[i].hist(jasmine[feat],  bins=40, alpha=0.6, label='Jasmine',  color='#DD8452')\n",
    "    axes[i].set_title(feat, fontsize=9, fontweight='bold')\n",
    "    axes[i].legend(fontsize=8)\n",
    "\n",
    "for j in range(i+1, len(axes)): axes[j].set_visible(False)\n",
    "plt.suptitle('Viz 1: Feature Distributions â€” Arborio vs Jasmine\\n'\n",
    "             'Separated peaks = strong discriminator | Overlapping = weak', fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 9: EDA â€” Visualisation 2: Correlation Heatmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "corr_matrix = rice_df[feature_columns].corr()\n",
    "mask        = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Hide upper triangle (mirror)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f',\n",
    "            cmap='RdYlGn', center=0, square=True, linewidths=0.5, ax=ax)\n",
    "ax.set_title('Viz 2: Feature Correlation Heatmap\\n'\n",
    "             'Near Â±1 = redundant pair | Near 0 = independent', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Flag highly correlated pairs\n",
    "print('Highly correlated pairs (|r| > 0.90):')\n",
    "found = False\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.90:\n",
    "            print(f'  {corr_matrix.columns[i]} â†” {corr_matrix.columns[j]}: {corr_matrix.iloc[i,j]:.3f}')\n",
    "            found = True\n",
    "if not found: print('  âœ… No highly redundant pairs found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 10: EDA â€” Visualisation 3: Pairplot of Top 5 Features â”€â”€\n",
    "# Rank features by effect size: how far apart are the two class means?\n",
    "effect_sizes = {\n",
    "    feat: abs(arborio[feat].mean() - jasmine[feat].mean()) / rice_df[feat].std()\n",
    "    for feat in feature_columns\n",
    "}\n",
    "top5 = sorted(effect_sizes, key=effect_sizes.get, reverse=True)[:5]\n",
    "\n",
    "print('Top 5 most discriminative features:')\n",
    "for r, f in enumerate(top5, 1): print(f'  {r}. {f}: {effect_sizes[f]:.3f}')\n",
    "\n",
    "pair_grid = sns.pairplot(\n",
    "    rice_df[top5 + ['CLASS']],\n",
    "    hue='CLASS',\n",
    "    palette={'Arborio': '#4C72B0', 'Jasmine': '#DD8452'},\n",
    "    diag_kind='kde',\n",
    "    plot_kws={'alpha': 0.4, 's': 15}\n",
    ")\n",
    "pair_grid.figure.suptitle('Viz 3: Pairplot â€” Top 5 Discriminative Features', y=1.02, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 11: Train / Validation / Test Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# stratify=y ensures each split has the same class ratio as the full dataset\n",
    "\n",
    "X = rice_df[feature_columns].values\n",
    "y = rice_df['label'].values\n",
    "\n",
    "X_tv, X_test,  y_tv, y_test  = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tv, y_tv, test_size=(0.15/0.85), random_state=RANDOM_SEED, stratify=y_tv)\n",
    "\n",
    "print(f'Train : {X_train.shape[0]} samples ({X_train.shape[0]/len(y)*100:.1f}%)')\n",
    "print(f'Val   : {X_val.shape[0]} samples ({X_val.shape[0]/len(y)*100:.1f}%)')\n",
    "print(f'Test  : {X_test.shape[0]} samples ({X_test.shape[0]/len(y)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 12: Feature Scaling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Fit ONLY on training data â€” never let val/test data influence the scaler\n",
    "\n",
    "scaler          = StandardScaler()\n",
    "X_train_scaled  = scaler.fit_transform(X_train)\n",
    "X_val_scaled    = scaler.transform(X_val)    # Same scaler, no refit\n",
    "X_test_scaled   = scaler.transform(X_test)   # Same scaler, no refit\n",
    "\n",
    "print('After scaling â€” training set stats (should be ~0 mean, ~1 std):')\n",
    "print(f'  Mean: {X_train_scaled.mean(axis=0)[:3].round(4)}  ...')\n",
    "print(f'  Std:  {X_train_scaled.std(axis=0)[:3].round(4)}   ...')\n",
    "print('âœ… Scaling complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Cell 13: Save Preprocessed Data for Part 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pickle\n",
    "\n",
    "data = {\n",
    "    'X_train': X_train_scaled, 'X_val': X_val_scaled, 'X_test': X_test_scaled,\n",
    "    'y_train': y_train,        'y_val': y_val,         'y_test': y_test,\n",
    "    'feature_columns': feature_columns,\n",
    "    'label_mapping': {'Arborio': 0, 'Jasmine': 1},\n",
    "    'scaler': scaler\n",
    "}\n",
    "\n",
    "with open('part1_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print('ðŸ’¾ Saved to part1_data.pkl')\n",
    "print('   â†’ Open Part 2 notebook next')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
